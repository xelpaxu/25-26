{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b07388",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "01170b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9212dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    \"\"\"\n",
    "    A Dense (Fully Connected) Layer for Neural Networks\n",
    "    \n",
    "    This class implements a dense layer with the following functionality:\n",
    "    - Setup/accept inputs and weights\n",
    "    - Perform weighted sum + bias\n",
    "    - Apply activation functions (ReLU, Sigmoid, Softmax)\n",
    "    - Calculate loss (Mean Squared Error)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, activation='relu'):\n",
    "        \"\"\"\n",
    "        Initialize the dense layer\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features\n",
    "            output_size (int): Number of output neurons\n",
    "            activation (str): Activation function ('relu', 'sigmoid', 'softmax')\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.inputs = None\n",
    "        self.weighted_sum = None\n",
    "        self.output = None\n",
    "    \n",
    "    def setup_weights_bias(self, weights, bias):\n",
    "        \"\"\"\n",
    "        Function to setup/accept the inputs and weights (10 points)\n",
    "        \n",
    "        Args:\n",
    "            weights (list or np.array): Weight matrix (input_size x output_size)\n",
    "            bias (list or np.array): Bias vector\n",
    "        \"\"\"\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        \n",
    "        # Validate dimensions - weights should be (input_size x output_size)\n",
    "        if self.weights.shape != (self.input_size, self.output_size):\n",
    "            print(f\"Warning: Expected weights shape {(self.input_size, self.output_size)}, got {self.weights.shape}\")\n",
    "        if self.bias.shape != (self.output_size,):\n",
    "            print(f\"Warning: Expected bias shape {(self.output_size,)}, got {self.bias.shape}\")\n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "        \"\"\"\n",
    "        Function to perform the weighted sum + bias (10 points)\n",
    "        \n",
    "        Args:\n",
    "            inputs (list or np.array): Input data\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Weighted sum + bias (before activation)\n",
    "        \"\"\"\n",
    "        self.inputs = np.array(inputs)\n",
    "        \n",
    "        # Perform matrix multiplication: W^T * X + B\n",
    "        # For neural networks: output = W^T √ó input + bias\n",
    "        self.weighted_sum = np.dot(self.weights.T, self.inputs) + self.bias\n",
    "        \n",
    "        return self.weighted_sum\n",
    "    \n",
    "    def apply_activation(self, z=None):\n",
    "        \"\"\"\n",
    "        Function to perform the selected activation function (15 points)\n",
    "        \n",
    "        Args:\n",
    "            z (np.array, optional): Input to activation function. If None, uses self.weighted_sum\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Output after applying activation function\n",
    "        \"\"\"\n",
    "        if z is None:\n",
    "            z = self.weighted_sum\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            self.output = self.relu(z)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.output = self.sigmoid(z)\n",
    "        elif self.activation == 'softmax':\n",
    "            self.output = self.softmax(z)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {self.activation}\")\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def relu(self, z):\n",
    "        \"\"\"ReLU activation function: max(0, z)\"\"\"\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"Sigmoid activation function: 1 / (1 + e^(-z))\"\"\"\n",
    "        # Clip z to prevent overflow\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        \"\"\"Softmax activation function for multi-class classification\"\"\"\n",
    "        # Subtract max for numerical stability\n",
    "        z_shifted = z - np.max(z)\n",
    "        exp_z = np.exp(z_shifted)\n",
    "        return exp_z / np.sum(exp_z)\n",
    "    \n",
    "    def calculate_loss(self, predicted_output, target_output):\n",
    "        \"\"\"\n",
    "        Function to calculate the loss (predicted output vs target output) (15 points)\n",
    "        \n",
    "        Args:\n",
    "            predicted_output (list or np.array): Model predictions\n",
    "            target_output (list or np.array): True target values\n",
    "            \n",
    "        Returns:\n",
    "            float: Mean Squared Error loss\n",
    "        \"\"\"\n",
    "        predicted = np.array(predicted_output)\n",
    "        target = np.array(target_output)\n",
    "        \n",
    "        # Mean Squared Error Loss\n",
    "        mse_loss = np.mean((predicted - target) ** 2)\n",
    "        \n",
    "        return mse_loss\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Complete forward pass: weighted sum + bias + activation\n",
    "        \n",
    "        Args:\n",
    "            inputs (list or np.array): Input data\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Final output after activation\n",
    "        \"\"\"\n",
    "        self.forward_pass(inputs)\n",
    "        return self.apply_activation()\n",
    "    \n",
    "    def get_layer_info(self):\n",
    "        \"\"\"\n",
    "        Get information about the layer\n",
    "        \n",
    "        Returns:\n",
    "            dict: Layer information\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'input_size': self.input_size,\n",
    "            'output_size': self.output_size,\n",
    "            'activation': self.activation,\n",
    "            'weights_shape': self.weights.shape if self.weights is not None else None,\n",
    "            'bias_shape': self.bias.shape if self.bias is not None else None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f72dd4",
   "metadata": {},
   "source": [
    "# Problem 1: Iris Dataset Classification\n",
    "\n",
    "**Problem Statement:** Given the following inputs from the Iris Dataset, using the sepal length, sepal width, petal length and petal width, determine what class (Iris-setosa, Iris-versicolor, and Iris-virginica) the following inputs are by calculating the output.\n",
    "\n",
    "**Input Data:**\n",
    "- X = [5.1, 3.5, 1.4, 0.2]\n",
    "- Target_output = [0.7, 0.2, 0.1]\n",
    "\n",
    "**Neural Network Configuration:**\n",
    "- **First Hidden Layer:** W1, B1, ReLU activation\n",
    "- **Second Hidden Layer:** W2, B2, Sigmoid activation  \n",
    "- **Output Layer:** W3, B3, Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39255b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Setup Complete!\n",
      "Input X: [5.1, 3.5, 1.4, 0.2]\n",
      "Target Output: [0.7, 0.2, 0.1]\n",
      "W1 shape: (4, 3) (4 inputs -> 3 outputs)\n",
      "W2 shape: (3, 2) (3 inputs -> 2 outputs)\n",
      "W3 shape: (2, 3) (2 inputs -> 3 outputs)\n"
     ]
    }
   ],
   "source": [
    "# Input data and target output\n",
    "X = [5.1, 3.5, 1.4, 0.2]\n",
    "Target_output = [0.7, 0.2, 0.1]\n",
    "\n",
    "# First Hidden Layer weights and bias\n",
    "# This is 4x3 matrix (4 inputs -> 3 outputs)\n",
    "W1 = [\n",
    "    [0.2, 0.5, -0.3],\n",
    "    [0.1, -0.2, 0.4],\n",
    "    [-0.4, 0.3, 0.2],\n",
    "    [0.6, -0.1, 0.5]\n",
    "]\n",
    "B1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "# Second Hidden Layer weights and bias\n",
    "# This is 3x2 matrix (3 inputs -> 2 outputs)\n",
    "W2 = [\n",
    "    [0.3, -0.5],\n",
    "    [0.7, 0.2],\n",
    "    [-0.6, 0.4]\n",
    "]\n",
    "B2 = [4.3, 6.4]\n",
    "\n",
    "# Output Layer weights and bias\n",
    "# This is 2x3 matrix (2 inputs -> 3 outputs)  \n",
    "W3 = [\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [-0.2, 0.6, -0.4]\n",
    "]\n",
    "B3 = [-1.5, 2.1, -3.3]\n",
    "\n",
    "print(\"Data Setup Complete!\")\n",
    "print(f\"Input X: {X}\")\n",
    "print(f\"Target Output: {Target_output}\")\n",
    "print(f\"W1 shape: {np.array(W1).shape} (4 inputs -> 3 outputs)\")\n",
    "print(f\"W2 shape: {np.array(W2).shape} (3 inputs -> 2 outputs)\")  \n",
    "print(f\"W3 shape: {np.array(W3).shape} (2 inputs -> 3 outputs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7907c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neural Network Layers...\n",
      "‚úì All layers created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network layers\n",
    "print(\"Creating Neural Network Layers...\")\n",
    "\n",
    "# Layer 1: Input(4) -> Hidden(3) with ReLU\n",
    "layer1 = Dense_Layer(input_size=4, output_size=3, activation='relu')\n",
    "layer1.setup_weights_bias(W1, B1)\n",
    "\n",
    "# Layer 2: Hidden(3) -> Hidden(2) with Sigmoid  \n",
    "layer2 = Dense_Layer(input_size=3, output_size=2, activation='sigmoid')\n",
    "layer2.setup_weights_bias(W2, B2)\n",
    "\n",
    "# Layer 3: Hidden(2) -> Output(3) with Softmax\n",
    "layer3 = Dense_Layer(input_size=2, output_size=3, activation='softmax')\n",
    "layer3.setup_weights_bias(W3, B3)\n",
    "\n",
    "print(\"‚úì All layers created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1a059d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LAYER 1: INPUT ‚Üí FIRST HIDDEN LAYER\n",
      "==================================================\n",
      "Input: [5.1, 3.5, 1.4, 0.2]\n",
      "Input shape: (4,)\n",
      "\n",
      "Weight matrix W1 (original):\n",
      "Shape: (4, 3)\n",
      "  Row 1: [ 0.2  0.5 -0.3]\n",
      "  Row 2: [ 0.1 -0.2  0.4]\n",
      "  Row 3: [-0.4  0.3  0.2]\n",
      "  Row 4: [ 0.6 -0.1  0.5]\n",
      "\n",
      "Weight matrix W1^T (transposed):\n",
      "Shape: (3, 4)\n",
      "  Row 1: [ 0.2  0.1 -0.4  0.6]  ‚Üê weights for output 1\n",
      "  Row 2: [ 0.5 -0.2  0.3 -0.1]  ‚Üê weights for output 2\n",
      "  Row 3: [-0.3  0.4  0.2  0.5]  ‚Üê weights for output 3\n",
      "\n",
      "Matrix multiplication: W1^T √ó X\n",
      "Result before bias: [0.93 2.25 0.25]\n",
      "After adding bias [3.0, -2.1, 0.6]: [3.93 0.15 0.85]\n",
      "After ReLU activation: [3.93 0.15 0.85]\n",
      "\n",
      "‚úì Layer 1 Output: [3.93 0.15 0.85]\n"
     ]
    }
   ],
   "source": [
    "# LAYER 1: Input -> First Hidden Layer\n",
    "print(\"=\"*50)\n",
    "print(\"LAYER 1: INPUT ‚Üí FIRST HIDDEN LAYER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Input: {X}\")\n",
    "print(f\"Input shape: {np.array(X).shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W1 (original):\")\n",
    "print(f\"Shape: {np.array(W1).shape}\")\n",
    "for i, row in enumerate(np.array(W1)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W1^T (transposed):\")\n",
    "W1_T = np.array(W1).T\n",
    "print(f\"Shape: {W1_T.shape}\")\n",
    "for i, row in enumerate(W1_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W1^T √ó X\")\n",
    "weighted_result = np.dot(W1_T, np.array(X))\n",
    "print(f\"Result before bias: {weighted_result}\")\n",
    "\n",
    "out1 = layer1.predict(X)\n",
    "print(f\"After adding bias {B1}: {layer1.weighted_sum}\")\n",
    "print(f\"After ReLU activation: {out1}\")\n",
    "print(f\"\\n‚úì Layer 1 Output: {out1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20ed4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LAYER 2: FIRST HIDDEN ‚Üí SECOND HIDDEN LAYER\n",
      "==================================================\n",
      "Input: [3.93 0.15 0.85]\n",
      "Input shape: (3,)\n",
      "\n",
      "Weight matrix W2 (original):\n",
      "Shape: (3, 2)\n",
      "  Row 1: [ 0.3 -0.5]\n",
      "  Row 2: [0.7 0.2]\n",
      "  Row 3: [-0.6  0.4]\n",
      "\n",
      "Weight matrix W2^T (transposed):\n",
      "Shape: (2, 3)\n",
      "  Row 1: [ 0.3  0.7 -0.6]  ‚Üê weights for output 1\n",
      "  Row 2: [-0.5  0.2  0.4]  ‚Üê weights for output 2\n",
      "\n",
      "Matrix multiplication: W2^T √ó out1\n",
      "Result before bias: [ 0.774 -1.595]\n",
      "After adding bias [4.3, 6.4]: [5.074 4.805]\n",
      "After Sigmoid activation: [0.99378157 0.99187781]\n",
      "\n",
      "‚úì Layer 2 Output: [0.99378157 0.99187781]\n"
     ]
    }
   ],
   "source": [
    "# LAYER 2: First Hidden -> Second Hidden Layer\n",
    "print(\"=\"*50)\n",
    "print(\"LAYER 2: FIRST HIDDEN ‚Üí SECOND HIDDEN LAYER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Input: {out1}\")\n",
    "print(f\"Input shape: {out1.shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W2 (original):\")\n",
    "print(f\"Shape: {np.array(W2).shape}\")\n",
    "for i, row in enumerate(np.array(W2)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W2^T (transposed):\")\n",
    "W2_T = np.array(W2).T\n",
    "print(f\"Shape: {W2_T.shape}\")\n",
    "for i, row in enumerate(W2_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W2^T √ó out1\")\n",
    "weighted_result2 = np.dot(W2_T, out1)\n",
    "print(f\"Result before bias: {weighted_result2}\")\n",
    "\n",
    "out2 = layer2.predict(out1)\n",
    "print(f\"After adding bias {B2}: {layer2.weighted_sum}\")\n",
    "print(f\"After Sigmoid activation: {out2}\")\n",
    "print(f\"\\n‚úì Layer 2 Output: {out2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "26d26250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LAYER 3: SECOND HIDDEN ‚Üí OUTPUT LAYER\n",
      "==================================================\n",
      "Input: [0.99378157 0.99187781]\n",
      "Input shape: (2,)\n",
      "\n",
      "Weight matrix W3 (original):\n",
      "Shape: (2, 3)\n",
      "  Row 1: [ 0.5 -0.3  0.8]\n",
      "  Row 2: [-0.2  0.6 -0.4]\n",
      "\n",
      "Weight matrix W3^T (transposed):\n",
      "Shape: (3, 2)\n",
      "  Row 1: [ 0.5 -0.2]  ‚Üê weights for output 1\n",
      "  Row 2: [-0.3  0.6]  ‚Üê weights for output 2\n",
      "  Row 3: [ 0.8 -0.4]  ‚Üê weights for output 3\n",
      "\n",
      "Matrix multiplication: W3^T √ó out2\n",
      "Result before bias: [0.29851522 0.29699221 0.39827413]\n",
      "After adding bias [-1.5, 2.1, -3.3]: [-1.20148478  2.39699221 -2.90172587]\n",
      "After Softmax activation: [0.0265075  0.96865119 0.00484132]\n",
      "\n",
      "‚úì Layer 3 Final Output: [0.0265075  0.96865119 0.00484132]\n"
     ]
    }
   ],
   "source": [
    "# LAYER 3: Second Hidden -> Output Layer\n",
    "print(\"=\"*50)\n",
    "print(\"LAYER 3: SECOND HIDDEN ‚Üí OUTPUT LAYER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Input: {out2}\")\n",
    "print(f\"Input shape: {out2.shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W3 (original):\")\n",
    "print(f\"Shape: {np.array(W3).shape}\")\n",
    "for i, row in enumerate(np.array(W3)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W3^T (transposed):\")\n",
    "W3_T = np.array(W3).T\n",
    "print(f\"Shape: {W3_T.shape}\")\n",
    "for i, row in enumerate(W3_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W3^T √ó out2\")\n",
    "weighted_result3 = np.dot(W3_T, out2)\n",
    "print(f\"Result before bias: {weighted_result3}\")\n",
    "\n",
    "final_output = layer3.predict(out2)\n",
    "print(f\"After adding bias {B3}: {layer3.weighted_sum}\")\n",
    "print(f\"After Softmax activation: {final_output}\")\n",
    "print(f\"\\n‚úì Layer 3 Final Output: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c9a18ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ============================================================\n",
      "üå∏ IRIS CLASSIFICATION FINAL RESULTS üå∏\n",
      "üéØ============================================================\n",
      "Final Output: [0.0265075  0.96865119 0.00484132]\n",
      "Target Output: [0.7, 0.2, 0.1]\n",
      "Loss (MSE): 0.3511573252826841\n",
      "\n",
      "üîç Classification Results:\n",
      "  Predicted Class: Iris-versicolor\n",
      "  Confidence: 0.9687\n",
      "\n",
      "üìä Class Probabilities:\n",
      "  Iris-setosa: 0.0265\n",
      "  Iris-versicolor: 0.9687\n",
      "  Iris-virginica: 0.0048\n",
      "\n",
      "üìù ASSIGNMENT ANSWERS:\n",
      "  Hidden Layer 2 (Output): [0.99378157 0.99187781]\n",
      "  Loss: 0.3511573252826841\n"
     ]
    }
   ],
   "source": [
    "# IRIS CLASSIFICATION RESULTS\n",
    "print(\"üéØ\" + \"=\"*60)\n",
    "print(\"üå∏ IRIS CLASSIFICATION FINAL RESULTS üå∏\")\n",
    "print(\"üéØ\" + \"=\"*60)\n",
    "\n",
    "print(f\"Final Output: {final_output}\")\n",
    "print(f\"Target Output: {Target_output}\")\n",
    "\n",
    "# Calculate loss\n",
    "loss = layer3.calculate_loss(final_output, Target_output)\n",
    "print(f\"Loss (MSE): {loss}\")\n",
    "\n",
    "# Determine predicted class\n",
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "predicted_index = np.argmax(final_output)\n",
    "predicted_class = classes[predicted_index]\n",
    "confidence = final_output[predicted_index]\n",
    "\n",
    "print(f\"\\nüîç Classification Results:\")\n",
    "print(f\"  Predicted Class: {predicted_class}\")\n",
    "print(f\"  Confidence: {confidence:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Class Probabilities:\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"  {class_name}: {final_output[i]:.4f}\")\n",
    "\n",
    "# Required Output Format for Assignment\n",
    "print(f\"\\nüìù ASSIGNMENT ANSWERS:\")\n",
    "print(f\"  Hidden Layer 2 (Output): {out2}\")\n",
    "print(f\"  Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba31b1",
   "metadata": {},
   "source": [
    "# Problem 2: Breast Cancer Dataset Classification\n",
    "\n",
    "**Problem Statement:** Given the following inputs from the Breast Cancer Dataset, using three features: Mean Radius, Mean Texture, and Mean Smoothness, determine whether the tumor is Benign (0) or Malignant (1) by calculating the network outputs step by step.\n",
    "\n",
    "**Input Data:**\n",
    "- X = [14.1, 20.3, 0.095]\n",
    "- Target_output = [1] (Malignant)\n",
    "\n",
    "**Neural Network Configuration:**\n",
    "- **First Hidden Layer:** W1, B1, ReLU activation\n",
    "- **Second Hidden Layer:** W2, B2, Sigmoid activation  \n",
    "- **Output Layer:** W3, B3, Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6cd14d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Breast Cancer Dataset Problem...\n",
      "Breast Cancer Data Setup Complete!\n",
      "Input X: [14.1, 20.3, 0.095]\n",
      "Target Output: [1]\n",
      "W1 shape: (3, 3) (3 inputs -> 3 outputs)\n",
      "W2 shape: (3, 2) (3 inputs -> 2 outputs)\n",
      "W3 shape: (2, 1) (2 inputs -> 1 output)\n"
     ]
    }
   ],
   "source": [
    "# Breast Cancer Dataset Problem Setup\n",
    "print(\"Setting up Breast Cancer Dataset Problem...\")\n",
    "\n",
    "# Input data and target output\n",
    "X_breast = [14.1, 20.3, 0.095]\n",
    "Target_output_breast = [1]  # Malignant\n",
    "\n",
    "# First Hidden Layer weights and bias\n",
    "# This is 3x3 matrix (3 inputs -> 3 outputs)\n",
    "W1_breast = [\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [0.2, 0.4, -0.6],\n",
    "    [-0.7, 0.9, 0.1]\n",
    "]\n",
    "B1_breast = [0.3, -0.5, 0.6]\n",
    "\n",
    "# Second Hidden Layer weights and bias\n",
    "# This is 3x2 matrix (3 inputs -> 2 outputs)\n",
    "W2_breast = [\n",
    "    [0.6, -0.2],\n",
    "    [0.4, -0.3],\n",
    "    [0.5, 0.7]\n",
    "]\n",
    "B2_breast = [0.1, -0.8]\n",
    "\n",
    "# Output Layer weights and bias\n",
    "# W3 from assignment: [0.7&-0.5]\n",
    "# This is 2x1 matrix (2 inputs -> 1 output)\n",
    "W3_breast = [\n",
    "    [0.7],\n",
    "    [-0.5]\n",
    "]\n",
    "B3_breast = [0.2]\n",
    "\n",
    "print(\"Breast Cancer Data Setup Complete!\")\n",
    "print(f\"Input X: {X_breast}\")\n",
    "print(f\"Target Output: {Target_output_breast}\")\n",
    "print(f\"W1 shape: {np.array(W1_breast).shape} (3 inputs -> 3 outputs)\")\n",
    "print(f\"W2 shape: {np.array(W2_breast).shape} (3 inputs -> 2 outputs)\")\n",
    "print(f\"W3 shape: {np.array(W3_breast).shape} (2 inputs -> 1 output)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68f347ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neural Network Layers for Breast Cancer Classification...\n",
      "‚úì All layers created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network layers for Breast Cancer classification\n",
    "print(\"Creating Neural Network Layers for Breast Cancer Classification...\")\n",
    "\n",
    "# Layer 1: Input(3) -> Hidden(3) with ReLU\n",
    "layer1_breast = Dense_Layer(input_size=3, output_size=3, activation='relu')\n",
    "layer1_breast.setup_weights_bias(W1_breast, B1_breast)\n",
    "\n",
    "# Layer 2: Hidden(3) -> Hidden(2) with Sigmoid\n",
    "layer2_breast = Dense_Layer(input_size=3, output_size=2, activation='sigmoid')\n",
    "layer2_breast.setup_weights_bias(W2_breast, B2_breast)\n",
    "\n",
    "# Layer 3: Hidden(2) -> Output(1) with Sigmoid\n",
    "layer3_breast = Dense_Layer(input_size=2, output_size=1, activation='sigmoid')\n",
    "layer3_breast.setup_weights_bias(W3_breast, B3_breast)\n",
    "\n",
    "print(\"‚úì All layers created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ad5c9ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫============================================================\n",
      "BREAST CANCER LAYER 1: INPUT ‚Üí FIRST HIDDEN LAYER\n",
      "ü©∫============================================================\n",
      "Input: [14.1, 20.3, 0.095]\n",
      "Input shape: (3,)\n",
      "\n",
      "Weight matrix W1_breast (original):\n",
      "Shape: (3, 3)\n",
      "  Row 1: [ 0.5 -0.3  0.8]\n",
      "  Row 2: [ 0.2  0.4 -0.6]\n",
      "  Row 3: [-0.7  0.9  0.1]\n",
      "\n",
      "Weight matrix W1_breast^T (transposed):\n",
      "Shape: (3, 3)\n",
      "  Row 1: [ 0.5  0.2 -0.7]  ‚Üê weights for output 1\n",
      "  Row 2: [-0.3  0.4  0.9]  ‚Üê weights for output 2\n",
      "  Row 3: [ 0.8 -0.6  0.1]  ‚Üê weights for output 3\n",
      "\n",
      "Matrix multiplication: W1_breast^T √ó X_breast\n",
      "Result before bias: [11.0435  3.9755 -0.8905]\n",
      "After adding bias [0.3, -0.5, 0.6]: [11.3435  3.4755 -0.2905]\n",
      "After ReLU activation: [11.3435  3.4755  0.    ]\n",
      "\n",
      "‚úì Layer 1 Output: [11.3435  3.4755  0.    ]\n"
     ]
    }
   ],
   "source": [
    "# BREAST CANCER LAYER 1: Input -> First Hidden Layer\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "print(\"BREAST CANCER LAYER 1: INPUT ‚Üí FIRST HIDDEN LAYER\")\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "\n",
    "print(f\"Input: {X_breast}\")\n",
    "print(f\"Input shape: {np.array(X_breast).shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W1_breast (original):\")\n",
    "print(f\"Shape: {np.array(W1_breast).shape}\")\n",
    "for i, row in enumerate(np.array(W1_breast)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W1_breast^T (transposed):\")\n",
    "W1_breast_T = np.array(W1_breast).T\n",
    "print(f\"Shape: {W1_breast_T.shape}\")\n",
    "for i, row in enumerate(W1_breast_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W1_breast^T √ó X_breast\")\n",
    "weighted_result1_breast = np.dot(W1_breast_T, X_breast)\n",
    "print(f\"Result before bias: {weighted_result1_breast}\")\n",
    "\n",
    "out1_breast = layer1_breast.predict(X_breast)\n",
    "print(f\"After adding bias {B1_breast}: {layer1_breast.weighted_sum}\")\n",
    "print(f\"After ReLU activation: {out1_breast}\")\n",
    "print(f\"\\n‚úì Layer 1 Output: {out1_breast}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "474e56c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫============================================================\n",
      "BREAST CANCER LAYER 2: FIRST HIDDEN ‚Üí SECOND HIDDEN LAYER\n",
      "ü©∫============================================================\n",
      "Input: [11.3435  3.4755  0.    ]\n",
      "Input shape: (3,)\n",
      "\n",
      "Weight matrix W2_breast (original):\n",
      "Shape: (3, 2)\n",
      "  Row 1: [ 0.6 -0.2]\n",
      "  Row 2: [ 0.4 -0.3]\n",
      "  Row 3: [0.5 0.7]\n",
      "\n",
      "Weight matrix W2_breast^T (transposed):\n",
      "Shape: (2, 3)\n",
      "  Row 1: [0.6 0.4 0.5]  ‚Üê weights for output 1\n",
      "  Row 2: [-0.2 -0.3  0.7]  ‚Üê weights for output 2\n",
      "\n",
      "Matrix multiplication: W2_breast^T √ó out1_breast\n",
      "Result before bias: [ 8.1963  -3.31135]\n",
      "After adding bias [0.1, -0.8]: [ 8.2963  -4.11135]\n",
      "After Sigmoid activation: [0.99975062 0.01612148]\n",
      "\n",
      "‚úì Layer 2 Output: [0.99975062 0.01612148]\n"
     ]
    }
   ],
   "source": [
    "# BREAST CANCER LAYER 2: First Hidden -> Second Hidden Layer\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "print(\"BREAST CANCER LAYER 2: FIRST HIDDEN ‚Üí SECOND HIDDEN LAYER\")\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "\n",
    "print(f\"Input: {out1_breast}\")\n",
    "print(f\"Input shape: {out1_breast.shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W2_breast (original):\")\n",
    "print(f\"Shape: {np.array(W2_breast).shape}\")\n",
    "for i, row in enumerate(np.array(W2_breast)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W2_breast^T (transposed):\")\n",
    "W2_breast_T = np.array(W2_breast).T\n",
    "print(f\"Shape: {W2_breast_T.shape}\")\n",
    "for i, row in enumerate(W2_breast_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W2_breast^T √ó out1_breast\")\n",
    "weighted_result2_breast = np.dot(W2_breast_T, out1_breast)\n",
    "print(f\"Result before bias: {weighted_result2_breast}\")\n",
    "\n",
    "out2_breast = layer2_breast.predict(out1_breast)\n",
    "print(f\"After adding bias {B2_breast}: {layer2_breast.weighted_sum}\")\n",
    "print(f\"After Sigmoid activation: {out2_breast}\")\n",
    "print(f\"\\n‚úì Layer 2 Output: {out2_breast}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cc3a6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫============================================================\n",
      "BREAST CANCER LAYER 3: SECOND HIDDEN ‚Üí OUTPUT LAYER\n",
      "ü©∫============================================================\n",
      "Input: [0.99975062 0.01612148]\n",
      "Input shape: (2,)\n",
      "\n",
      "Weight matrix W3_breast (original):\n",
      "Shape: (2, 1)\n",
      "  Row 1: [0.7]\n",
      "  Row 2: [-0.5]\n",
      "\n",
      "Weight matrix W3_breast^T (transposed):\n",
      "Shape: (1, 2)\n",
      "  Row 1: [ 0.7 -0.5]  ‚Üê weights for output 1\n",
      "\n",
      "Matrix multiplication: W3_breast^T √ó out2_breast\n",
      "Result before bias: [0.6917647]\n",
      "After adding bias [0.2]: [0.8917647]\n",
      "After Sigmoid activation: [0.70925421]\n",
      "\n",
      "‚úì Layer 3 Final Output: [0.70925421]\n"
     ]
    }
   ],
   "source": [
    "# BREAST CANCER LAYER 3: Second Hidden -> Output Layer\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "print(\"BREAST CANCER LAYER 3: SECOND HIDDEN ‚Üí OUTPUT LAYER\")\n",
    "print(\"ü©∫\" + \"=\"*60)\n",
    "\n",
    "print(f\"Input: {out2_breast}\")\n",
    "print(f\"Input shape: {out2_breast.shape}\")\n",
    "\n",
    "# Show transpose operation\n",
    "print(f\"\\nWeight matrix W3_breast (original):\")\n",
    "print(f\"Shape: {np.array(W3_breast).shape}\")\n",
    "for i, row in enumerate(np.array(W3_breast)):\n",
    "    print(f\"  Row {i+1}: {row}\")\n",
    "\n",
    "print(f\"\\nWeight matrix W3_breast^T (transposed):\")\n",
    "W3_breast_T = np.array(W3_breast).T\n",
    "print(f\"Shape: {W3_breast_T.shape}\")\n",
    "for i, row in enumerate(W3_breast_T):\n",
    "    print(f\"  Row {i+1}: {row}  ‚Üê weights for output {i+1}\")\n",
    "\n",
    "print(f\"\\nMatrix multiplication: W3_breast^T √ó out2_breast\")\n",
    "weighted_result3_breast = np.dot(W3_breast_T, out2_breast)\n",
    "print(f\"Result before bias: {weighted_result3_breast}\")\n",
    "\n",
    "final_output_breast = layer3_breast.predict(out2_breast)\n",
    "print(f\"After adding bias {B3_breast}: {layer3_breast.weighted_sum}\")\n",
    "print(f\"After Sigmoid activation: {final_output_breast}\")\n",
    "print(f\"\\n‚úì Layer 3 Final Output: {final_output_breast}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fe1ae37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ======================================================================\n",
      "ü©∫ BREAST CANCER CLASSIFICATION FINAL RESULTS ü©∫\n",
      "üéØ======================================================================\n",
      "Final Output: 0.709254\n",
      "Target Output: 1\n",
      "Loss (MSE): 0.084533\n",
      "\n",
      "üîç Classification Results:\n",
      "  Predicted Class: Malignant (0.709254)\n",
      "  Actual Class: Malignant\n",
      "  Prediction: ‚úÖ Correct\n",
      "\n",
      "üìä Classification Probabilities:\n",
      "  Benign: 0.290746\n",
      "  Malignant: 0.709254\n",
      "\n",
      "üìù ASSIGNMENT ANSWERS:\n",
      "  Hidden Layer 2 (Output): [0.99975062 0.01612148]\n",
      "  Loss: 0.0845331144305979\n"
     ]
    }
   ],
   "source": [
    "# BREAST CANCER CLASSIFICATION RESULTS\n",
    "print(\"üéØ\" + \"=\"*70)\n",
    "print(\"ü©∫ BREAST CANCER CLASSIFICATION FINAL RESULTS ü©∫\")\n",
    "print(\"üéØ\" + \"=\"*70)\n",
    "\n",
    "print(f\"Final Output: {final_output_breast[0]:.6f}\")\n",
    "print(f\"Target Output: {Target_output_breast[0]}\")\n",
    "\n",
    "# Calculate loss\n",
    "loss_breast = layer3_breast.calculate_loss(final_output_breast, Target_output_breast)\n",
    "print(f\"Loss (MSE): {loss_breast:.6f}\")\n",
    "\n",
    "# Determine predicted class\n",
    "threshold = 0.5\n",
    "predicted_class_breast = \"Malignant\" if final_output_breast[0] > threshold else \"Benign\"\n",
    "actual_class_breast = \"Malignant\" if Target_output_breast[0] == 1 else \"Benign\"\n",
    "\n",
    "print(f\"\\nüîç Classification Results:\")\n",
    "print(f\"  Predicted Class: {predicted_class_breast} ({final_output_breast[0]:.6f})\")\n",
    "print(f\"  Actual Class: {actual_class_breast}\")\n",
    "print(f\"  Prediction: {'‚úÖ Correct' if predicted_class_breast == actual_class_breast else '‚ùå Incorrect'}\")\n",
    "\n",
    "# Classification probabilities\n",
    "print(f\"\\nüìä Classification Probabilities:\")\n",
    "print(f\"  Benign: {1 - final_output_breast[0]:.6f}\")\n",
    "print(f\"  Malignant: {final_output_breast[0]:.6f}\")\n",
    "\n",
    "# Required Output Format for Assignment\n",
    "print(f\"\\nüìù ASSIGNMENT ANSWERS:\")\n",
    "print(f\"  Hidden Layer 2 (Output): {out2_breast}\")\n",
    "print(f\"  Loss: {loss_breast}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
