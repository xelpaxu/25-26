{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f0dc06",
   "metadata": {},
   "source": [
    "# Unit 2: Dense Layer Implementation\n",
    "**Author:** Herald Kent Amolong  \n",
    "**Date:** September 11, 2025\n",
    "\n",
    "Implementation of a Dense_Layer class for neural networks with:\n",
    "- Input/weights setup function\n",
    "- Weighted sum + bias function  \n",
    "- Activation functions (ReLU, Sigmoid, Softmax)\n",
    "- Loss calculation (Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56bf9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244f222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_Layer class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.z = None\n",
    "        self.output = None\n",
    "    \n",
    "    def set_inputs_and_weights(self, inputs, weights, bias):\n",
    "        \"\"\"Store input values, weights, and bias\"\"\"\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "    \n",
    "    def weighted_sum(self):\n",
    "        \"\"\"Compute z = np.dot(inputs, weights) + bias\"\"\"\n",
    "        if self.inputs is None or self.weights is None or self.bias is None:\n",
    "            raise ValueError(\"Inputs, weights, and bias must be set first!\")\n",
    "        self.z = np.dot(self.inputs, self.weights) + self.bias\n",
    "        return self.z\n",
    "    \n",
    "    def activation(self, function=\"relu\"):\n",
    "        \"\"\"Apply activation function: relu, sigmoid, or softmax\"\"\"\n",
    "        if self.z is None:\n",
    "            raise ValueError(\"Must compute weighted sum first!\")\n",
    "        \n",
    "        if function == \"relu\":\n",
    "            self.output = np.maximum(0, self.z)\n",
    "        elif function == \"sigmoid\":\n",
    "            self.output = 1 / (1 + np.exp(-np.clip(self.z, -500, 500)))\n",
    "        elif function == \"softmax\":\n",
    "            z_shifted = self.z - np.max(self.z)\n",
    "            exp_values = np.exp(z_shifted)\n",
    "            self.output = exp_values / np.sum(exp_values)\n",
    "        else:\n",
    "            raise ValueError(\"Supported functions: 'relu', 'sigmoid', 'softmax'\")\n",
    "        return self.output\n",
    "    \n",
    "    def calculate_loss(self, predicted, target):\n",
    "        \"\"\"Compute cross-entropy loss\"\"\"\n",
    "        predicted = np.array(predicted)\n",
    "        target = np.array(target)\n",
    "        epsilon = 1e-15\n",
    "        predicted = np.clip(predicted, epsilon, 1 - epsilon)\n",
    "        loss = -np.sum(target * np.log(predicted))\n",
    "        return loss\n",
    "\n",
    "print(\"Dense_Layer class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25710372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized with sample input and weights\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Setup\n",
    "sample_input = np.array([5.1, 3.5, 1.4, 0.2])\n",
    "target_output = np.array([0.7, 0.2, 0.1])\n",
    "\n",
    "# Weights and Biases\n",
    "W1 = np.array([[0.2, 0.5, -0.3], [0.1, -0.2, 0.4], [-0.4, 0.3, 0.2], [0.6, -0.1, 0.5]])\n",
    "B1 = np.array([3.0, -2.1, 0.6])\n",
    "\n",
    "W2 = np.array([[0.3, -0.5], [0.7, 0.2], [-0.6, 0.4]])\n",
    "B2 = np.array([4.3, 6.4])\n",
    "\n",
    "W3 = np.array([[0.5, -0.3, 0.8], [-0.2, 0.6, -0.4]])\n",
    "B3 = np.array([-1.5, 2.1, -3.3])\n",
    "\n",
    "print(\"Network initialized with sample input and weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794117a8",
   "metadata": {},
   "source": [
    "## Forward Pass Implementation\n",
    "1. Input → Hidden Layer 1 (ReLU)\n",
    "2. Hidden Layer 1 → Hidden Layer 2 (Sigmoid)  \n",
    "3. Hidden Layer 2 → Output Layer (Softmax)\n",
    "4. Loss Calculation (Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f190be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORWARD PASS ===\n",
      "Hidden Layer 1 (ReLU): [3.93 0.15 0.85]\n",
      "Hidden Layer 2 (Sigmoid): [0.99378157 0.99187781]\n",
      "Output Layer (Softmax): [0.0265075  0.96865119 0.00484132]\n",
      "Cross-entropy Loss: 3.080656\n",
      "Predicted: Versicolor (0.9687)\n"
     ]
    }
   ],
   "source": [
    "# Complete Forward Pass\n",
    "print(\"=== FORWARD PASS ===\")\n",
    "\n",
    "# Layer 1: Input → Hidden Layer 1 (ReLU)\n",
    "layer1 = Dense_Layer()\n",
    "layer1.set_inputs_and_weights(sample_input, W1, B1)\n",
    "z1 = layer1.weighted_sum()\n",
    "hidden1_output = layer1.activation(\"relu\")\n",
    "print(f\"Hidden Layer 1 (ReLU): {hidden1_output}\")\n",
    "\n",
    "# Layer 2: Hidden Layer 1 → Hidden Layer 2 (Sigmoid)\n",
    "layer2 = Dense_Layer()\n",
    "layer2.set_inputs_and_weights(hidden1_output, W2, B2)\n",
    "z2 = layer2.weighted_sum()\n",
    "hidden2_output = layer2.activation(\"sigmoid\")\n",
    "print(f\"Hidden Layer 2 (Sigmoid): {hidden2_output}\")\n",
    "\n",
    "# Layer 3: Hidden Layer 2 → Output Layer (Softmax)\n",
    "layer3 = Dense_Layer()\n",
    "layer3.set_inputs_and_weights(hidden2_output, W3, B3)\n",
    "z3 = layer3.weighted_sum()\n",
    "final_output = layer3.activation(\"softmax\")\n",
    "print(f\"Output Layer (Softmax): {final_output}\")\n",
    "\n",
    "# Loss Calculation\n",
    "loss = layer3.calculate_loss(final_output, target_output)\n",
    "print(f\"Cross-entropy Loss: {loss:.6f}\")\n",
    "\n",
    "# Prediction\n",
    "class_names = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predicted_class_idx = np.argmax(final_output)\n",
    "predicted_class = class_names[predicted_class_idx]\n",
    "confidence = final_output[predicted_class_idx]\n",
    "print(f\"Predicted: {predicted_class} ({confidence:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a08033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPLETE RESULTS ===\n",
      "Input: [5.1 3.5 1.4 0.2]\n",
      "Target: [0.7 0.2 0.1]\n",
      "Hidden Layer 1: [3.93 0.15 0.85]\n",
      "Hidden Layer 2: [0.99378157 0.99187781]\n",
      "Output: [0.0265075  0.96865119 0.00484132]\n",
      "Loss: 3.080656\n",
      "Prediction: Versicolor (0.9687)\n",
      "\n",
      "=== Architecture ===\n",
      "Total Parameters: 32\n",
      "✅ All required functions implemented and tested!\n"
     ]
    }
   ],
   "source": [
    "# Results Summary\n",
    "print(\"\\n=== COMPLETE RESULTS ===\")\n",
    "print(f\"Input: {sample_input}\")\n",
    "print(f\"Target: {target_output}\")\n",
    "print(f\"Hidden Layer 1: {hidden1_output}\")\n",
    "print(f\"Hidden Layer 2: {hidden2_output}\")\n",
    "print(f\"Output: {final_output}\")\n",
    "print(f\"Loss: {loss:.6f}\")\n",
    "print(f\"Prediction: {predicted_class} ({confidence:.4f})\")\n",
    "\n",
    "print(f\"\\n=== Architecture ===\")\n",
    "total_params = W1.size + B1.size + W2.size + B2.size + W3.size + B3.size\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(\"✅ All required functions implemented and tested!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef0cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE FORWARD PASS SUMMARY\n",
      "================================================================================\n",
      "Input: [5.1 3.5 1.4 0.2]\n",
      "Target: [0.7 0.2 0.1] (Iris-setosa)\n",
      "\n",
      "Layer           Shape           Activation      Output Values\n",
      "--------------------------------------------------------------------------------\n",
      "Input           (4,)            None            [5.1 3.5 1.4 0.2]\n",
      "Hidden 1        (3,)            ReLU            [3.93 0.15 0.85]\n",
      "Hidden 2        (2,)            Sigmoid         [0.99378157 0.99187781]\n",
      "Output          (3,)            Softmax         [0.0265075  0.96865119 0.00484132]\n",
      "\n",
      "Metrics              Value\n",
      "----------------------------------------\n",
      "Predicted Class      Versicolor\n",
      "Confidence           0.9687\n",
      "Cross-Entropy Loss   3.080656\n",
      "Correct Prediction   False\n",
      "\n",
      "=== Architecture Summary ===\n",
      "Total Parameters:\n",
      "  - W1: 12, B1: 3\n",
      "  - W2: 6, B2: 2\n",
      "  - W3: 6, B3: 3\n",
      "  - Total: 32 parameters\n"
     ]
    }
   ],
   "source": [
    "# Complete Forward Pass Summary\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE FORWARD PASS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Input: {sample_input}\")\n",
    "print(f\"Target: {target_output} (Iris-setosa)\")\n",
    "\n",
    "print(f\"\\n{'Layer':<15} {'Shape':<15} {'Activation':<15} {'Output Values'}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Input':<15} {str(sample_input.shape):<15} {'None':<15} {sample_input}\")\n",
    "print(f\"{'Hidden 1':<15} {str(hidden1_output.shape):<15} {'ReLU':<15} {hidden1_output}\")\n",
    "print(f\"{'Hidden 2':<15} {str(hidden2_output.shape):<15} {'Sigmoid':<15} {hidden2_output}\")\n",
    "print(f\"{'Output':<15} {str(final_output.shape):<15} {'Softmax':<15} {final_output}\")\n",
    "\n",
    "print(f\"\\n{'Metrics':<20} {'Value'}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Predicted Class':<20} {predicted_class}\")\n",
    "print(f\"{'Confidence':<20} {confidence:.4f}\")\n",
    "print(f\"{'Cross-Entropy Loss':<20} {loss:.6f}\")\n",
    "print(f\"{'Correct Prediction':<20} {predicted_class == 'Setosa'}\")\n",
    "\n",
    "print(f\"\\n=== Architecture Summary ===\")\n",
    "print(f\"Total Parameters:\")\n",
    "total_params = (W1.size + B1.size + W2.size + B2.size + W3.size + B3.size)\n",
    "print(f\"  - W1: {W1.size}, B1: {B1.size}\")\n",
    "print(f\"  - W2: {W2.size}, B2: {B2.size}\")\n",
    "print(f\"  - W3: {W3.size}, B3: {B3.size}\")\n",
    "print(f\"  - Total: {total_params} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
