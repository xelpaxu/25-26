{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7efe702",
   "metadata": {},
   "source": [
    "Number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423c3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Student Pass/Fail Perceptron \n",
      "\n",
      "Configuration: w1=0.6, w2=0.4, bias=-3, threshold=1\n",
      "\n",
      "Test 1: Input (x1=8, x2=7)\n",
      "  Weighted sum: (0.6 × 8) + (0.4 × 7) + (-3) = 4.6\n",
      "  Is 4.6 >= 1? True\n",
      "  Output: 1 (PASS)\n",
      "\n",
      "Test 2: Input (x1=3, x2=4)\n",
      "  Weighted sum: (0.6 × 3) + (0.4 × 4) + (-3) = 0.3999999999999999\n",
      "  Is 0.3999999999999999 >= 1? False\n",
      "  Output: 0 (FAIL)\n"
     ]
    }
   ],
   "source": [
    "def perceptron_step_function(weighted_sum, threshold):\n",
    "    \"\"\"\n",
    "    Step activation function\n",
    "    Returns 1 if weighted_sum >= threshold, else 0\n",
    "    \"\"\"\n",
    "    return 1 if weighted_sum >= threshold else 0\n",
    "\n",
    "def student_pass_fail_perceptron(x1, x2, w1=0.6, w2=0.4, bias=-3, threshold=1):\n",
    "    \"\"\"\n",
    "    Perceptron to determine if student passes or fails\n",
    "    x1: hours studied\n",
    "    x2: hours of sleep\n",
    "    \"\"\"\n",
    "    # Calculate weighted sum\n",
    "    weighted_sum = (w1 * x1) + (w2 * x2) + bias\n",
    "    \n",
    "    # Apply activation function\n",
    "    output = perceptron_step_function(weighted_sum, threshold)\n",
    "    \n",
    "    return output, weighted_sum\n",
    "\n",
    "# Test cases\n",
    "print(\" Student Pass/Fail Perceptron \\n\")\n",
    "print(f\"Configuration: w1=0.6, w2=0.4, bias=-3, threshold=1\\n\")\n",
    "\n",
    "# Test case 1\n",
    "x1_test1, x2_test1 = 8, 7\n",
    "output1, sum1 = student_pass_fail_perceptron(x1_test1, x2_test1)\n",
    "print(f\"Test 1: Input (x1={x1_test1}, x2={x2_test1})\")\n",
    "print(f\"  Weighted sum: (0.6 × {x1_test1}) + (0.4 × {x2_test1}) + (-3) = {sum1}\")\n",
    "print(f\"  Is {sum1} >= 1? {sum1 >= 1}\")\n",
    "print(f\"  Output: {output1} ({'PASS' if output1 == 1 else 'FAIL'})\\n\")\n",
    "\n",
    "# Test case 2\n",
    "x1_test2, x2_test2 = 3, 4\n",
    "output2, sum2 = student_pass_fail_perceptron(x1_test2, x2_test2)\n",
    "print(f\"Test 2: Input (x1={x1_test2}, x2={x2_test2})\")\n",
    "print(f\"  Weighted sum: (0.6 × {x1_test2}) + (0.4 × {x2_test2}) + (-3) = {sum2}\")\n",
    "print(f\"  Is {sum2} >= 1? {sum2 >= 1}\")\n",
    "print(f\"  Output: {output2} ({'PASS' if output2 == 1 else 'FAIL'})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2200f6",
   "metadata": {},
   "source": [
    "Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0198448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AND Gate Perceptron ===\n",
      "\n",
      "Configuration: w1=1, w2=1, bias=-1.5, threshold=0\n",
      "\n",
      "Truth Table Verification:\n",
      "\n",
      "Input (x1, x2)  Weighted Sum    Output     AND Gate   Match     \n",
      "------------------------------------------------------------\n",
      "(0, 0)            -1.5            0          0          ✓         \n",
      "(0, 1)            -0.5            0          0          ✓         \n",
      "(1, 0)            -0.5            0          0          ✓         \n",
      "(1, 1)            0.5             1          1          ✓         \n",
      "------------------------------------------------------------\n",
      "\n",
      "Verification Result: PASSED - Acts as AND gate\n"
     ]
    }
   ],
   "source": [
    "def perceptron_step_function(weighted_sum, threshold):\n",
    "    \"\"\"\n",
    "    Step activation function\n",
    "    Returns 1 if weighted_sum >= threshold, else 0\n",
    "    \"\"\"\n",
    "    return 1 if weighted_sum >= threshold else 0\n",
    "\n",
    "def and_gate_perceptron(x1, x2, w1=1, w2=1, bias=-1.5, threshold=0):\n",
    "    \"\"\"\n",
    "    AND gate perceptron implementation\n",
    "    Returns output and weighted sum\n",
    "    \"\"\"\n",
    "    # Calculate weighted sum\n",
    "    weighted_sum = (w1 * x1) + (w2 * x2) + bias\n",
    "    \n",
    "    # Apply activation function\n",
    "    output = perceptron_step_function(weighted_sum, threshold)\n",
    "    \n",
    "    return output, weighted_sum\n",
    "\n",
    "# Test all input combinations\n",
    "print(\"=== AND Gate Perceptron ===\\n\")\n",
    "print(f\"Configuration: w1=1, w2=1, bias=-1.5, threshold=0\\n\")\n",
    "\n",
    "# Define test inputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "and_gate_truth = [0, 0, 0, 1]  # Expected AND gate outputs\n",
    "\n",
    "print(\"Truth Table Verification:\\n\")\n",
    "print(f\"{'Input (x1, x2)':<15} {'Weighted Sum':<15} {'Output':<10} {'AND Gate':<10} {'Match':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "all_match = True\n",
    "for i, (x1, x2) in enumerate(test_inputs):\n",
    "    output, weighted_sum = and_gate_perceptron(x1, x2)\n",
    "    expected = and_gate_truth[i]\n",
    "    match = \"✓\" if output == expected else \"✗\"\n",
    "    \n",
    "    if output != expected:\n",
    "        all_match = False\n",
    "    \n",
    "    print(f\"({x1}, {x2})            {weighted_sum:<15.1f} {output:<10} {expected:<10} {match:<10}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nVerification Result: {'PASSED - Acts as AND gate' if all_match else 'FAILED - Does not act as AND gate'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f879",
   "metadata": {},
   "source": [
    "Number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Perceptron One vs All Classification ===\n",
      "\n",
      "Input: [ 0.5 -1.   2.   1.   0. ]\n",
      "\n",
      "Perceptron      Weighted Sum         Threshold       Output    \n",
      "------------------------------------------------------------\n",
      "A               1.70                 1.0             1         \n",
      "B               0.50                 1.0             0         \n",
      "C               0.15                 1.0             0         \n",
      "------------------------------------------------------------\n",
      "\n",
      "Winner Determination:\n",
      "------------------------------------------------------------\n",
      "Single Winner: Perceptron A\n",
      "  Output: 1\n",
      "  Weighted Sum: 1.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_step_function(weighted_sum, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Step activation function\n",
    "    Returns 1 if weighted_sum >= threshold, else 0\n",
    "    \"\"\"\n",
    "    return 1 if weighted_sum >= threshold else 0\n",
    "\n",
    "def compute_perceptron_output(inputs, weights, bias, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Compute perceptron output given inputs, weights, and bias\n",
    "    Returns: (output, weighted_sum)\n",
    "    \"\"\"\n",
    "    # Calculate weighted sum\n",
    "    weighted_sum = np.dot(inputs, weights) + bias\n",
    "    \n",
    "    # Apply activation function\n",
    "    output = perceptron_step_function(weighted_sum, threshold)\n",
    "    \n",
    "    return output, weighted_sum\n",
    "\n",
    "# Define problem parameters\n",
    "inputs = np.array([0.5, -1, 2, 1, 0])\n",
    "\n",
    "# Perceptron configurations\n",
    "perceptrons = {\n",
    "    'A': {'weights': np.array([1.0, -0.5, 0.2, 0.1, 0.0]), 'bias': 0.2},\n",
    "    'B': {'weights': np.array([0.2, 0.2, 0.5, -0.4, 0.3]), 'bias': 0.0},\n",
    "    'C': {'weights': np.array([-0.3, -0.1, 0.4, 0.0, 0.2]), 'bias': -0.6}\n",
    "}\n",
    "\n",
    "# Compute outputs\n",
    "print(\"=== Perceptron One vs All Classification ===\\n\")\n",
    "print(f\"Input: {inputs}\\n\")\n",
    "print(f\"{'Perceptron':<15} {'Weighted Sum':<20} {'Threshold':<15} {'Output':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results = {}\n",
    "for name, config in perceptrons.items():\n",
    "    output, weighted_sum = compute_perceptron_output(\n",
    "        inputs, \n",
    "        config['weights'], \n",
    "        config['bias'], \n",
    "        threshold=1.0\n",
    "    )\n",
    "    results[name] = {'output': output, 'weighted_sum': weighted_sum}\n",
    "    \n",
    "    print(f\"{name:<15} {weighted_sum:<20.2f} {1.0:<15} {output:<10}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Determine winner\n",
    "print(\"\\nWinner Determination:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Find perceptrons with output 1\n",
    "winners = [name for name, result in results.items() if result['output'] == 1]\n",
    "\n",
    "if len(winners) == 0:\n",
    "    print(\"No winner - all perceptrons output 0\")\n",
    "elif len(winners) == 1:\n",
    "    winner = winners[0]\n",
    "    print(f\"Single Winner: Perceptron {winner}\")\n",
    "    print(f\"  Output: {results[winner]['output']}\")\n",
    "    print(f\"  Weighted Sum: {results[winner]['weighted_sum']:.2f}\")\n",
    "else:\n",
    "    # Tie-breaker: highest weighted sum\n",
    "    highest_weighted = max(winners, key=lambda x: results[x]['weighted_sum'])\n",
    "    print(f\"Tie between: {', '.join(winners)}\")\n",
    "    print(f\"Tie-breaker (Highest Weighted Sum): Perceptron {highest_weighted}\")\n",
    "    print(f\"  Weighted Sum: {results[highest_weighted]['weighted_sum']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "School",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
